# auto_mpvoc_integrator.py
import json
import yaml
import hashlib
import requests
from datetime import datetime, timedelta
from pathlib import Path
import pandas as pd
from sentence_transformers import SentenceTransformer, util
import torch
from typing import List, Dict, Any
import re
from dataclasses import dataclass
from enum import Enum
import asyncio
import aiohttp

class ConceptCategory(Enum):
    CORE_META_ENTRY = "core_meta_entry"
    FOUNDATIONAL_ARCHITECTURE = "foundational_architecture"
    INDEX_TOOL = "index_tool"
    ANALYTICAL_CONCEPT = "analytical_concept"
    HIGH_RISK_TERM = "high_risk_term"
    EPISTEMIC_SAFEGUARD = "epistemic_safeguard"
    EMERGING_CONCEPT = "emerging_concept"

@dataclass
class MPTConcept:
    """Structured representation of an MPT-SST concept"""
    term: str
    acronym: str
    definition: str
    category: ConceptCategory
    source: str
    version: str
    added_date: datetime
    last_updated: datetime
    related_terms: List[str]
    resonance_score: float = 0.0
    embedding: Any = None
    validation_status: str = "pending"  # pending, validated, deprecated
    cross_references: Dict[str, str] = None
    
    def to_dict(self):
        return {
            "term": self.term,
            "acronym": self.acronym,
            "definition": self.definition,
            "category": self.category.value,
            "source": self.source,
            "version": self.version,
            "added_date": self.added_date.isoformat(),
            "last_updated": self.last_updated.isoformat(),
            "related_terms": self.related_terms,
            "resonance_score": self.resonance_score,
            "validation_status": self.validation_status,
            "cross_references": self.cross_references or {}
        }

class AutoMPVOCIntegrator:
    """Automatic system for integrating new MPT-SST concepts into the Cybernetic Peace Loop"""
    
    def __init__(self, repository_url: str = None):
        self.repository_url = repository_url or "https://kmptssty-eng.github.io/mpt-sst-website/concepts/"
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.concepts_db = self._load_concepts_database()
        self.concept_embeddings = {}
        self.update_history = []
        self._initialize_embeddings()
        
    def _load_concepts_database(self):
        """Load existing concepts database"""
        db_file = Path("mpvoc_concepts_database.json")
        if db_file.exists():
            with open(db_file, 'r') as f:
                data = json.load(f)
                return {item['term']: MPTConcept(**{
                    **item,
                    'category': ConceptCategory(item['category']),
                    'added_date': datetime.fromisoformat(item['added_date']),
                    'last_updated': datetime.fromisoformat(item['last_updated'])
                }) for item in data}
        return {}
    
    def _initialize_embeddings(self):
        """Create embeddings for all concepts"""
        for term, concept in self.concepts_db.items():
            if concept.embedding is None:
                text = f"{concept.term} {concept.acronym} {concept.definition}"
                concept.embedding = self.model.encode(text, convert_to_tensor=True)
            self.concept_embeddings[term] = concept.embedding
    
    def parse_encyclopedia_update(self, update_text: str) -> List[MPTConcept]:
        """Parse the provided MPVOC encyclopedia update"""
        concepts = []
        
        # Parse sections based on the provided structure
        sections = {
            "A. CORE META-ENTRY": ConceptCategory.CORE_META_ENTRY,
            "B. FOUNDATIONAL ARCHITECTURES": ConceptCategory.FOUNDATIONAL_ARCHITECTURE,
            "C. INDICES AND TOOLS": ConceptCategory.INDEX_TOOL,
            "D. KEY ANALYTICAL CONCEPTS": ConceptCategory.ANALYTICAL_CONCEPT,
            "E. REDEFINED HIGH-RISK TERMS": ConceptCategory.HIGH_RISK_TERM,
            "F. EPISTEMIC SAFEGUARDS": ConceptCategory.EPISTEMIC_SAFEGUARD
        }
        
        current_section = None
        current_concept = None
        lines = update_text.split('\n')
        
        for i, line in enumerate(lines):
            line = line.strip()
            
            # Check for section headers
            for section_header, category in sections.items():
                if line.startswith(section_header):
                    current_section = category
                    current_concept = None
                    break
            
            # Extract term with acronym pattern
            term_match = re.match(r'([A-Z][A-Za-z\s\-]+(?:\([A-Z]+\))?)', line)
            if term_match and current_section and len(line) < 200:
                # This might be a term definition
                term = term_match.group(1).strip()
                
                # Look for acronym in parentheses
                acronym_match = re.search(r'\(([A-Z]+)\)', term)
                acronym = acronym_match.group(1) if acronym_match else ""
                term_clean = re.sub(r'\s*\([A-Z]+\)', '', term)
                
                # Gather definition (next lines until empty line or next term)
                definition_lines = []
                for j in range(i + 1, min(i + 10, len(lines))):
                    next_line = lines[j].strip()
                    if not next_line or next_line in sections or re.match(r'[A-Z][A-Za-z\s\-]+(?:\([A-Z]+\))?', next_line):
                        break
                    definition_lines.append(next_line)
                
                definition = ' '.join(definition_lines)
                
                if definition:  # Only create concept if we have a definition
                    concept = MPTConcept(
                        term=term_clean,
                        acronym=acronym,
                        definition=definition,
                        category=current_section,
                        source="MPVOC Encyclopedia Update",
                        version="2024.1.0",
                        added_date=datetime.now(),
                        last_updated=datetime.now(),
                        related_terms=self._extract_related_terms(definition),
                        resonance_score=self._calculate_resonance_score(definition)
                    )
                    concepts.append(concept)
        
        return concepts
    
    def _extract_related_terms(self, definition: str) -> List[str]:
        """Extract related terms from definition"""
        # Look for MPT-SST specific terms
        related = set()
        
        # Common MPT patterns
        patterns = [
            r'MPT-SST',
            r'[A-Z]{3,5}',  # Acronyms like REA, CRC, RMO
            r'consciousness',
            r'resonance',
            r'coherence',
            r'metaphysical',
            r'peace',
            r'structural',
            r'transformation'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, definition, re.IGNORECASE)
            related.update([m.lower() for m in matches])
        
        return list(related)[:10]  # Limit to top 10
    
    def _calculate_resonance_score(self, definition: str) -> float:
        """Calculate initial resonance score based on definition content"""
        positive_indicators = [
            'coherence', 'alignment', 'harmony', 'integration',
            'sustainable', 'ethical', 'inclusive', 'reflexive',
            'developmental', 'diagnostic', 'anticipatory'
        ]
        
        negative_indicators = [
            'conflict', 'violence', 'coercion', 'dominance',
            'absolutism', 'deterministic', 'surveillance'
        ]
        
        text_lower = definition.lower()
        pos_count = sum(1 for word in positive_indicators if word in text_lower)
        neg_count = sum(1 for word in negative_indicators if word in text_lower)
        
        total_words = len(text_lower.split())
        if total_words == 0:
            return 0.5
        
        resonance = 0.5 + (pos_count - neg_count) / (2 * total_words)
        return max(0.0, min(1.0, resonance))
    
    def detect_new_concepts(self, parsed_concepts: List[MPTConcept]) -> List[MPTConcept]:
        """Detect concepts not already in database"""
        new_concepts = []
        
        for concept in parsed_concepts:
            # Check if concept already exists
            existing = self.concepts_db.get(concept.term)
            
            if not existing:
                # New concept
                new_concepts.append(concept)
            else:
                # Check if definition has changed significantly
                existing_embedding = existing.embedding
                new_embedding = self.model.encode(
                    f"{concept.term} {concept.definition}",
                    convert_to_tensor=True
                )
                
                similarity = util.pytorch_cos_sim(existing_embedding, new_embedding).item()
                
                if similarity < 0.8:  # Significant change
                    # Update existing concept
                    existing.definition = concept.definition
                    existing.last_updated = datetime.now()
                    existing.version = concept.version
                    existing.embedding = new_embedding
                    print(f"Updated concept: {concept.term} (similarity: {similarity:.3f})")
        
        return new_concepts
    
    def integrate_concepts(self, new_concepts: List[MPTConcept], auto_validate: bool = False):
        """Integrate new concepts into the system"""
        
        for concept in new_concepts:
            # Generate embedding
            concept.embedding = self.model.encode(
                f"{concept.term} {concept.acronym} {concept.definition}",
                convert_to_tensor=True
            )
            
            # Auto-validation based on rules
            if auto_validate:
                concept.validation_status = self._auto_validate_concept(concept)
            else:
                concept.validation_status = "pending"
            
            # Add to database
            self.concepts_db[concept.term] = concept
            self.concept_embeddings[concept.term] = concept.embedding
            
            # Update MPVOC classification files
            self._update_mpvoc_files(concept)
            
            # Log the integration
            self.update_history.append({
                "timestamp": datetime.now().isoformat(),
                "concept": concept.term,
                "category": concept.category.value,
                "action": "added" if concept.validation_status == "validated" else "pending",
                "resonance_score": concept.resonance_score
            })
            
            print(f"Integrated concept: {concept.term} ({concept.category.value})")
    
    def _auto_validate_concept(self, concept: MPTConcept) -> str:
        """Automatically validate concept based on rules"""
        
        validation_rules = [
            # Rule 1: Definition length
            (len(concept.definition.split()) >= 10, "Definition too short"),
            
            # Rule 2: Contains key MPT-SST terminology
            (any(term in concept.definition.lower() for term in 
                ['peace', 'consciousness', 'coherence', 'resonance']), 
                "Missing core MPT-SST terminology"),
            
            # Rule 3: Resonance score threshold
            (concept.resonance_score >= 0.3, "Low resonance score"),
            
            # Rule 4: Not a duplicate of existing concept
            (self._check_concept_uniqueness(concept), "Potential duplicate concept"),
        ]
        
        # Count passed rules
        passed = sum(1 for rule, _ in validation_rules if rule)
        
        if passed >= 3:
            return "validated"
        elif passed >= 2:
            return "review_needed"
        else:
            return "rejected"
    
    def _check_concept_uniqueness(self, concept: MPTConcept) -> bool:
        """Check if concept is unique compared to existing ones"""
        if not self.concept_embeddings:
            return True
        
        concept_embedding = self.model.encode(
            f"{concept.term} {concept.definition}",
            convert_to_tensor=True
        )
        
        # Compare with all existing concepts
        for existing_term, existing_embedding in self.concept_embeddings.items():
            similarity = util.pytorch_cos_sim(concept_embedding, existing_embedding).item()
            if similarity > 0.9:  # Very similar
                return False
        
        return True
    
    def _update_mpvoc_files(self, concept: MPTConcept):
        """Update various MPVOC files based on concept type"""
        
        # Load existing MPVOC files
        base_path = Path("data")
        
        # Update resonant terms if concept has high resonance
        if concept.resonance_score >= 0.7 and concept.validation_status == "validated":
            resonant_file = base_path / "mpvoc_resonant.json"
            if resonant_file.exists():
                with open(resonant_file, 'r') as f:
                    resonant_terms = json.load(f)
                
                if concept.term not in resonant_terms:
                    resonant_terms.append(concept.term)
                    with open(resonant_file, 'w') as f:
                        json.dump(resonant_terms, f, indent=2)
        
        # Update concept definitions file
        concepts_file = base_path / "mpvoc_concepts_detailed.json"
        concepts_data = {}
        if concepts_file.exists():
            with open(concepts_file, 'r') as f:
                concepts_data = json.load(f)
        
        concepts_data[concept.term] = concept.to_dict()
        with open(concepts_file, 'w') as f:
            json.dump(concepts_data, f, indent=2, ensure_ascii=False)
    
    async def monitor_external_sources(self):
        """Monitor external sources for new MPT-SST concepts"""
        sources = [
            self.repository_url,
            "https://www.researchgate.net/profile/Aliyu-Kafinga",
            "https://scholar.google.com/citations?user=YOUR_USER_ID"
        ]
        
        async with aiohttp.ClientSession() as session:
            tasks = []
            for source in sources:
                tasks.append(self._check_source_updates(session, source))
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            new_concepts = []
            for result in results:
                if isinstance(result, list):
                    new_concepts.extend(result)
            
            return new_concepts
    
    async def _check_source_updates(self, session, source_url: str):
        """Check a specific source for updates"""
        try:
            async with session.get(source_url, timeout=10) as response:
                if response.status == 200:
                    content = await response.text()
                    
                    # Parse content for MPT-SST concepts
                    # This would be source-specific parsing logic
                    # For now, return empty list
                    return []
        except Exception as e:
            print(f"Error checking source {source_url}: {e}")
        
        return []
    
    def generate_concept_report(self) -> Dict:
        """Generate report on integrated concepts"""
        total_concepts = len(self.concepts_db)
        validated = sum(1 for c in self.concepts_db.values() 
                       if c.validation_status == "validated")
        pending = sum(1 for c in self.concepts_db.values() 
                     if c.validation_status == "pending")
        
        categories = {}
        for concept in self.concepts_db.values():
            cat = concept.category.value
            categories[cat] = categories.get(cat, 0) + 1
        
        recent_updates = sorted(
            self.update_history,
            key=lambda x: x['timestamp'],
            reverse=True
        )[:10]
        
        return {
            "report_date": datetime.now().isoformat(),
            "total_concepts": total_concepts,
            "validated_concepts": validated,
            "pending_concepts": pending,
            "categories": categories,
            "recent_updates": recent_updates,
            "system_status": "operational"
        }
    
    def save_database(self):
        """Save concepts database to file"""
        db_file = Path("mpvoc_concepts_database.json")
        data = [concept.to_dict() for concept in self.concepts_db.values()]
        
        with open(db_file, 'w') as f:
            json.dump(data, f, indent=2, default=str)
        
        # Also save report
        report = self.generate_concept_report()
        report_file = Path("mpvoc_integration_report.json")
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"Database saved: {db_file}")
        print(f"Report saved: {report_file}")
    
    def create_dashboard_module(self):
        """Create Streamlit module for concept management"""
        dashboard_code = '''
import streamlit as st
import pandas as pd
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go

def concept_management_dashboard():
    st.title("üîÑ Auto-MPVOC Concept Integrator")
    st.markdown("**Automatic integration of new MPT-SST concepts into the Cybernetic Peace Loop**")
    
    # Load concepts database
    try:
        with open("mpvoc_concepts_database.json", "r") as f:
            concepts_data = json.load(f)
        
        df = pd.DataFrame(concepts_data)
        
        # Statistics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total Concepts", len(df))
        with col2:
            validated = len(df[df["validation_status"] == "validated"])
            st.metric("Validated", validated)
        with col3:
            pending = len(df[df["validation_status"] == "pending"])
            st.metric("Pending", pending)
        with col4:
            avg_resonance = df["resonance_score"].mean()
            st.metric("Avg Resonance", f"{avg_resonance:.2f}")
        
        # Concept categories visualization
        st.subheader("üìä Concept Categories")
        category_counts = df["category"].value_counts()
        
        fig1 = px.pie(
            values=category_counts.values,
            names=category_counts.index,
            title="Concept Distribution by Category"
        )
        st.plotly_chart(fig1, use_container_width=True)
        
        # Recent additions
        st.subheader("üìà Recent Concept Additions")
        df["added_date"] = pd.to_datetime(df["added_date"])
        recent_df = df.sort_values("added_date", ascending=False).head(5)
        
        for _, row in recent_df.iterrows():
            with st.expander(f"{row['term']} ({row['category']})"):
                st.markdown(f"**Acronym:** {row['acronym']}")
                st.markdown(f"**Status:** {row['validation_status']}")
                st.markdown(f"**Resonance:** {row['resonance_score']:.3f}")
                st.markdown(f"**Definition:** {row['definition'][:200]}...")
        
        # Validation queue
        st.subheader("‚è≥ Validation Queue")
        pending_df = df[df["validation_status"] == "pending"]
        
        if not pending_df.empty:
            for _, row in pending_df.iterrows():
                col1, col2, col3 = st.columns([3, 1, 1])
                with col1:
                    st.write(f"**{row['term']}**")
                    st.caption(row['definition'][:100] + "...")
                with col2:
                    if st.button("Validate", key=f"val_{row['term']}"):
                        # Update validation status
                        st.success(f"Validated {row['term']}")
                with col3:
                    if st.button("Reject", key=f"rej_{row['term']}"):
                        st.error(f"Rejected {row['term']}")
        else:
            st.success("No pending concepts for validation")
        
        # Manual concept addition
        st.subheader("‚ûï Add New Concept Manually")
        with st.form("add_concept_form"):
            term = st.text_input("Concept Term")
            acronym = st.text_input("Acronym (optional)")
            definition = st.text_area("Definition", height=150)
            category = st.selectbox("Category", [
                "core_meta_entry", "foundational_architecture", 
                "index_tool", "analytical_concept",
                "high_risk_term", "epistemic_safeguard"
            ])
            
            submitted = st.form_submit_button("Add Concept")
            if submitted and term and definition:
                # Add to system
                st.success(f"Concept '{term}' added to validation queue")
        
        # System controls
        st.subheader("‚öôÔ∏è System Controls")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üîÑ Check for Updates"):
                with st.spinner("Checking for new concepts..."):
                    # Call update function
                    st.success("Update check complete")
        
        with col2:
            if st.button("üìä Generate Report"):
                with st.spinner("Generating report..."):
                    # Generate report
                    st.success("Report generated")
        
        with col3:
            if st.button("üíæ Save Database"):
                with st.spinner("Saving..."):
                    # Save database
                    st.success("Database saved")
    
    except FileNotFoundError:
        st.error("Concepts database not found. Please run the integrator first.")

if __name__ == "__main__":
    concept_management_dashboard()
'''
        
        dashboard_file = Path("auto_mpvoc_dashboard.py")
        with open(dashboard_file, 'w') as f:
            f.write(dashboard_code)
        
        print(f"Dashboard module created: {dashboard_file}")

# ===== EXECUTION =====
if __name__ == "__main__":
    print("\n" + "="*70)
    print("AUTO-MPVOC CONCEPT INTEGRATOR")
    print("="*70)
    
    # Initialize integrator
    integrator = AutoMPVOCIntegrator()
    
    # Read the encyclopedia update text
    with open("mpvoc_encyclopedia_update.txt", "r") as f:
        encyclopedia_text = f.read()
    
    print("\nüìö Parsing MPVOC Encyclopedia Update...")
    parsed_concepts = integrator.parse_encyclopedia_update(encyclopedia_text)
    print(f"   Found {len(parsed_concepts)} concepts in update")
    
    print("\nüîç Detecting new concepts...")
    new_concepts = integrator.detect_new_concepts(parsed_concepts)
    print(f"   Found {len(new_concepts)} new concepts")
    
    if new_concepts:
        print("\nüîÑ Integrating new concepts...")
        integrator.integrate_concepts(new_concepts, auto_validate=True)
        
        print("\nüìä Generating report...")
        report = integrator.generate_concept_report()
        
        print(f"\n‚úÖ Integration Complete:")
        print(f"   Total concepts in system: {report['total_concepts']}")
        print(f"   Newly validated: {report['validated_concepts'] - len(integrator.concepts_db) + len(new_concepts)}")
        print(f"   By category:")
        for category, count in report['categories'].items():
            print(f"     - {category}: {count}")
        
        # Save database
        integrator.save_database()
        
        # Create dashboard module
        print("\nüìà Creating management dashboard...")
        integrator.create_dashboard_module()
        
        print("\n" + "="*70)
        print("AUTOMATIC INTEGRATION SYSTEM READY")
        print("="*70)
        print("\nThe system can now:")
        print("1. Automatically detect new MPT-SST concepts")
        print("2. Validate them against epistemological standards")
        print("3. Integrate into the Cybernetic Peace Loop")
        print("4. Update MPVOC classification files")
        print("5. Provide real-time monitoring via dashboard")
        
        print("\nüöÄ Next: Deploy the auto-update system with periodic monitoring")
        
    else:
        print("\n‚ÑπÔ∏è No new concepts to integrate.")
